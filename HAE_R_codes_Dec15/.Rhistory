neg_days$posIdMatched <- c(rep(NA, length(neg_days)-length(posIds_forMatched)), posIds_forMatched)
length(neg_days)-length(posIds_forMatched)
length(neg_days)
dat_neg$posIdMatched <- c(rep(NA, nrow(dat_neg)-length(posIds_forMatched)), posIds_forMatched)
dat_neg$posIdMatched[1:100]
posIdMatched <- c(rep(NA, nrow(dat_neg)-length(posIds_forMatched)), posIds_forMatched)
save(posIdMatched, file=paste0(result_dir, 'posIdMatched.RData'))
match <- function(i){
d <- neg_nested[i, 1]
d_lw=d-30
d_up=d+30
freq <- neg_nested[i, 2]
posId <- c()
posDay <- c()
for(d_pos in days_pos){
if(d_pos <= d_up & d_pos >= d_lw){
posDay <- c(posDay, d_pos)
}
}
if(length(posId)>0){
posId <- dat_pos[match(posDay, dat_pos$ids), "lookback_days"]
posIds_forMatch <- sample(posId, size=freq, replace=T)
}else{
posIds_forMatch <- NA
}
temp <- list(neg_days=d, posIds=posId, posIds_forMatch=posIds_forMatch)
return(temp)
}
sfInit(parallel=TRUE, cpus=39, type='SOCK')
#sfSource("F:\\Jie\\Shire\\03_code\\subFunc_v3.R")
#sfSource("F:\\Jie\\Shire_follow_up\\02_Code\\clean_split_featureSelection_lasso.R")
sfExport('neg_nested', 'days_pos')
sfExport('match')
#sfClusterEval(library("glmnet"))
t0 <- proc.time()
result <- sfClusterApplyLB(1:nrow(neg_nested), match)
sfStop()
cat('time used:', (proc.time()-t0)[3]/60, 'min!\n')
neg_days <- unlist(lapply(result, function(x)x[[1]]))
pos_days_list <- lapply(result, function(x)x[[2]])
posIds_forMatch <- lapply(result, function(x)x[[3]])
bUnmatched <- unlist(lapply(posIds_forMatch, function(x){
any(is.na(x))
}))
idx_unmatched <- which(bUnmatched==T)
neg_days_unmatched <- neg_days[idx_unmatched]
posIds_forMatch_vct <- unlist(posIds_forMatch)
posIds_forMatched <- posIds_forMatch_vct[!is.na(posIds_forMatch_vct)] #[1] 246550
dat_neg_matched <- dat_neg[!(dat_neg$lookback_days %in% neg_days_unmatched), ] #[1] 246550      2
dat_neg_unmatched <- dat_neg[dat_neg$lookback_days %in% neg_days_unmatched, ]
dat_neg$posIdMatched <- c(rep(NA, nrow(dat_neg)-length(posIds_forMatched)), posIds_forMatched)
posIdMatched <- c(rep(NA, nrow(dat_neg)-length(posIds_forMatched)), posIds_forMatched)
posIdMatched[1:100]
posIdMatched
i=1
d <- neg_nested[i, 1]
d_lw=d-30
d_up=d+30
freq <- neg_nested[i, 2]
posId <- c()
posDay <- c()
for(d_pos in days_pos){
if(d_pos <= d_up & d_pos >= d_lw){
posDay <- c(posDay, d_pos)
}
}
posDay
if(length(posId)>0){
posId <- dat_pos[match(posDay, dat_pos$ids), "lookback_days"]
posIds_forMatch <- sample(posId, size=freq, replace=T)
}else{
posIds_forMatch <- NA
}
posIds_forMatch
i=1000
d <- neg_nested[i, 1]
d_lw=d-30
d_up=d+30
freq <- neg_nested[i, 2]
posId <- c()
posDay <- c()
for(d_pos in days_pos){
if(d_pos <= d_up & d_pos >= d_lw){
posDay <- c(posDay, d_pos)
}
}
posDay
posId <- dat_pos[match(posDay, dat_pos$ids), "lookback_days"]
posIds_forMatch <- sample(posId, size=freq, replace=T)
head(dat_pos)
posDay
match(posDay, dat_pos$ids)
dat_pos$ids
match(posDay, dat_pos$ids)
match(seq(1, 10), seq(1, 5))
match(1, 2)
posId <- dat_pos[dat_pos$ids %in% posDay, "lookback_days"]
posIds_forMatch <- sample(posId, size=freq, replace=T)
posId
dat_pos$ids %in% posDay
posId <- dat_pos$lookback_days[dat_pos$ids %in% posDay]
posId
posId <- dat_pos$ids[dat_pos$lookback_days %in% posDay]
posId
posIds_forMatch <- sample(posId, size=freq, replace=T)
match <- function(i){
d <- neg_nested[i, 1]
d_lw=d-30
d_up=d+30
freq <- neg_nested[i, 2]
posId <- c()
posDay <- c()
for(d_pos in days_pos){
if(d_pos <= d_up & d_pos >= d_lw){
posDay <- c(posDay, d_pos)
}
}
if(length(posDay)>0){
posId <- dat_pos$ids[dat_pos$lookback_days %in% posDay]
posIds_forMatch <- sample(posId, size=freq, replace=T)
}else{
posIds_forMatch <- NA
}
temp <- list(neg_days=d, posIds=posId, posIds_forMatch=posIds_forMatch)
return(temp)
}
sfInit(parallel=TRUE, cpus=39, type='SOCK')
#sfSource("F:\\Jie\\Shire\\03_code\\subFunc_v3.R")
#sfSource("F:\\Jie\\Shire_follow_up\\02_Code\\clean_split_featureSelection_lasso.R")
sfExport('neg_nested', 'days_pos')
sfExport('match')
#sfClusterEval(library("glmnet"))
t0 <- proc.time()
result <- sfClusterApplyLB(1:nrow(neg_nested), match)
sfStop()
cat('time used:', (proc.time()-t0)[3]/60, 'min!\n')
neg_days <- unlist(lapply(result, function(x)x[[1]]))
pos_days_list <- lapply(result, function(x)x[[2]])
posIds_forMatch <- lapply(result, function(x)x[[3]])
bUnmatched <- unlist(lapply(posIds_forMatch, function(x){
any(is.na(x))
}))
idx_unmatched <- which(bUnmatched==T)
neg_days_unmatched <- neg_days[idx_unmatched]
posIds_forMatch_vct <- unlist(posIds_forMatch)
posIds_forMatched <- posIds_forMatch_vct[!is.na(posIds_forMatch_vct)] #[1] 246550
# dat_neg_matched <- dat_neg %>%
#     filter(., lookback_days %in% neg_days_unmatched)
dat_neg_matched <- dat_neg[!(dat_neg$lookback_days %in% neg_days_unmatched), ] #[1] 246550      2
dat_neg_unmatched <- dat_neg[dat_neg$lookback_days %in% neg_days_unmatched, ]
dat_neg$posIdMatched <- c(rep(NA, nrow(dat_neg)-length(posIds_forMatched)), posIds_forMatched)
posIdMatched <- c(rep(NA, nrow(dat_neg)-length(posIds_forMatched)), posIds_forMatched)
save(posIdMatched, file=paste0(result_dir, 'posIdMatched.RData'))
match <- function(i){
d <- neg_nested[i, 1]
d_lw=d-30
d_up=d+30
freq <- neg_nested[i, 2]
posId <- c()
posDay <- c()
for(d_pos in days_pos){
if(d_pos <= d_up & d_pos >= d_lw){
posDay <- c(posDay, d_pos)
}
}
if(length(posDay)>0){
posId <- dat_pos$ids[dat_pos$lookback_days %in% posDay]
posIds_forMatch <- sample(posId, size=freq, replace=T)
}else{
posIds_forMatch <- NA
}
temp <- list(neg_days=d, posIds=posId, posIds_forMatch=posIds_forMatch)
return(temp)
}
sfInit(parallel=TRUE, cpus=39, type='SOCK')
#sfSource("F:\\Jie\\Shire\\03_code\\subFunc_v3.R")
#sfSource("F:\\Jie\\Shire_follow_up\\02_Code\\clean_split_featureSelection_lasso.R")
sfExport('neg_nested', 'days_pos', 'dat_pos')
sfExport('match')
#sfClusterEval(library("glmnet"))
t0 <- proc.time()
result <- sfClusterApplyLB(1:nrow(neg_nested), match)
sfStop()
cat('time used:', (proc.time()-t0)[3]/60, 'min!\n')
neg_days <- unlist(lapply(result, function(x)x[[1]]))
pos_days_list <- lapply(result, function(x)x[[2]])
posIds_forMatch <- lapply(result, function(x)x[[3]])
bUnmatched <- unlist(lapply(posIds_forMatch, function(x){
any(is.na(x))
}))
idx_unmatched <- which(bUnmatched==T)
neg_days_unmatched <- neg_days[idx_unmatched]
posIds_forMatch_vct <- unlist(posIds_forMatch)
posIds_forMatched <- posIds_forMatch_vct[!is.na(posIds_forMatch_vct)] #[1] 246550
# dat_neg_matched <- dat_neg %>%
#     filter(., lookback_days %in% neg_days_unmatched)
dat_neg_matched <- dat_neg[!(dat_neg$lookback_days %in% neg_days_unmatched), ] #[1] 246550      2
dat_neg_unmatched <- dat_neg[dat_neg$lookback_days %in% neg_days_unmatched, ]
dat_neg$posIdMatched <- c(rep(NA, nrow(dat_neg)-length(posIds_forMatched)), posIds_forMatched)
posIdMatched <- c(rep(NA, nrow(dat_neg)-length(posIds_forMatched)), posIds_forMatched)
save(posIdMatched, file=paste0(result_dir, 'posIdMatched.RData'))
posIdMatched[1:100]
dim(dat_neg_unmatched)
max(posIdMatched)
max(posIdMatched, na.rm = T)
min(posIdMatched, na.rm = T)
load("F:\\Jie\\Shire_follow_up\\03_Results\\for200+\\splitedDataB4ModelTsSim1.RData")
ls()
names(ts)
load("F:\\Jie\\Shire_follow_up\\03_Results\\for200+\\splitedDataB4ModelTrVlSim1.RData")
ls()
names(trVl)
load("F:\\Jie\\Shire_follow_up\\03_Results\\for200+a\\splitedDataB4ModelTrVlSim1.RData")
names(trVl)
library(xlsx)
library(ROCR)
library(plyr)
library(caret)
library(dplyr)
library(glmnet)
library(snow)
library(snowfall)
library(caTools)
source("F:\\Jie\\Shire_follow_up\\02_Code\\clean_split_featureSelection_lasso.R")
n.simu <- 5
n.folds <- 5
source("F:\\Jie\\Shire_follow_up\\02_Code\\clean_split_featureSelection_lasso1.R")
run_lasso(dataDir='F:\\Jie\\Shire_follow_up\\03_Results\\for200+a\\'
, resultDir="F:\\Jie\\Shire_follow_up\\03_Results\\for200+a\\"
, norm=F
, n.folds=5
, wt=0.005
, crit=0.05
, Btest=T
, crit_nm='auc')
run_lasso(dataDir='F:\\Jie\\Shire_follow_up\\03_Results\\for200+a\\'
, resultDir="F:\\Jie\\Shire_follow_up\\03_Results\\for200+a\\"
, norm=F
, n.folds=5
, wt=0.005
, crit=0.05
, Btest=F
, crit_nm='auc')
library(rJava)
install.packages("rJava")
library(rJava)
library(rJava)
library(rJava)
library(rJava)
rm(list=ls())
# R work directory
wk_dir = "F:\\Jie\\Shire_follow_up\\02_Code\\HAE_R_codes_Dec15\\"
# Setup R work directory
setwd(wk_dir)
# Load R packages
source("loadpackage.R")
# Auxiliary functions
source("auxfunctions.R")
#
source("funs_baggingRF.R")
get_perf_2.5M_par <- function(simu, outDir, lasso_rf_iters, recall_tar, fileNm_2.5M, path_2.5M){
plots_path <- paste0(outDir, 'iters=', lasso_rf_iters, '\\simu', simu, '\\')
if(!dir.exists(plots_path)){dir.create(plots_path, showWarnings = T, recursive = T, model='0777')}
#     x_3M <- read.table(paste0(path_2.5M, fileNm_2.5M, ".csv")
#                        , sep=','
#                        , stringsAsFactors = F
#                        , head=T
#     )
x_3M <- lapply(1, function(i) {
load(paste0(path_2.5M, fileNm_2.5M, '_', i, '.RData'))
return(adj_ppv_samp)
})
x_3M <- ldply(x_3M, rbind)
load(paste0(plots_path, 'trn_rf_fit_Mar31.RData'))
vars_rf <- rownames(trn_undbag_rf_fit[[1]]$importance)
if('LOOKBACK_DAYS' %in% vars_rf & 'lookback_days' %in% names(x_3M)){
x_3M <- x_3M %>% mutate(LOOKBACK_DAYS=lookback_days) %>% select(-PATIENT_ID) %>% select(-lookback_days)
}
load(paste0(outDir, 'dat_hae_trn_tst_split_simu', simu, '.RData'))
rm(dat_hae_trn, dat_nonhae_trn, dat_nonhae_tst)
gc()
tst_prob_rf = rep(0, nrow(x_3M))
tst_prob_rf_hae = rep(0, nrow(dat_hae_tst)) #218
Sys.time()->start
# Logistic regression
# tst_prob_logit = predict(trn_logit_fit, dat_tst[,-match('HAE', names(dat_tst))], type="response")
# Bagging LASSO, Bagging Random Forest
for (i in 1:lasso_rf_iters){
# 	tst_prob_lasso = tst_prob_lasso + predict(trn_undbag_lasso_fit[[i]], as.matrix(x_tst), s="lambda.min", type="response")/lasso_rf_iters
cat('i=', i, '!\n')
tst_prob_rf = tst_prob_rf + predict(trn_undbag_rf_fit[[i]], x_3M, type = "prob")[,2]/lasso_rf_iters
tst_prob_rf_hae = tst_prob_rf_hae + predict(trn_undbag_rf_fit[[i]], dat_hae_tst[,-match(c('HAE', 'PATIENT_ID'), names(dat_hae_tst))], type = "prob")[,2]/lasso_rf_iters
}
print(Sys.time()-start)
# Time difference of 12.26336 mins
save( tst_prob_rf_hae, tst_prob_rf, file=paste(plots_path, "tst_rf_prob_haeTs&2.5M.RData", sep=""))
resp <- c(rep(1, length(tst_prob_rf_hae)), rep(0, length(tst_prob_rf)))
pred <- c(tst_prob_rf_hae, tst_prob_rf)
perf_result <- msOnTest_sep_v2(pred, resp, recall_tar=seq(0.5, 0.05, -0.05))
write.csv(perf_result$ms, paste0(plots_path, 'perf_on2.5M.csv'))
result <- c(simu=simu, perf_result$ms)
return(result)
}
run_perf_2.5M <- function(outDir, lasso_rf_iters, n.simu, recall_tar, fileNm_2.5M, path_2.5M){
trace_path <- paste0(outDir, 'iters=', lasso_rf_iters, '\\')
if(!dir.exists(trace_path)) dir.create(trace_path, showWarnings = T, recursive = TRUE)
traceFile <- paste0(trace_path, 'traceFile_pred2.5M.csv')
cat(file=traceFile, append=T, 'parallele on n.simu simulation start!\n')
wk_dir = "F:\\Jie\\Shire_follow_up\\02_Code\\HAE_R_codes_Dec15\\"
sfInit(parallel=TRUE, cpus=n.simu, type='SOCK')
#sfSource("F:\\Jie\\Shire\\03_code\\subFunc_v3.R")
cat(file=traceFile, append=TRUE, 'n.simu simulations parallel sfExport running!\n')
sfExport(  'outDir', 'wk_dir')
sfExport('get_perf_2.5M_par', 'msOnTest_sep_v2'
)
sfSource(paste0(wk_dir, "loadpackage.R"))
# Auxiliary functions
sfSource(paste0(wk_dir, "auxfunctions.R"))
#
sfSource(paste0(wk_dir, "funs_baggingRF.R"))
sfClusterEval(library(ggplot2))
sfClusterEval(library(ROCR))
sfClusterEval(library(PRROC))
# sfClusterEval(library(FSelector))
sfClusterEval(library(randomForest))
sfClusterEval(library(caret))
sfClusterEval(library(e1071))
sfClusterEval(library(reshape2))
sfClusterEval(library(sqldf))
sfClusterEval(library(glmnet))
sfClusterEval(library(caTools))
# sfClusterEval(library(gbm))
# sfClusterEval(library(xlsx))
sfClusterEval(library(dplyr))
temp <- sfClusterApplyLB(1:n.simu, get_perf_2.5M_par
, outDir
, lasso_rf_iters
, recall_tar
, fileNm_2.5M
, path_2.5M
)
#save(pred_ts_allSim, file=paste0(modelDir, '//pred_allSim.RData'))
sfStop()
ms_allSimu <- ldply(temp, quickdf)
return(ms_allSimu)
}
t0 <- proc.time()
perf_Dong_1simu_on2.5M <- run_perf_2.5M(outDir="F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233(oneSimu)\\"
, lasso_rf_iters=200
, n.simu=1
, recall_tar=seq(0.5, 0.05, -0.05)
, fileNm_2.5M='adj_ppv_samp'
, path_2.5M='F:\\Dong\\share\\Rep_Samp\\'
)
cat((proc.time()-t0)[3]/60, 'min!\n')
perf_Dong_1simu_on2.5M
perf_new200_973_iter20 <- get_perf_allSimu(outdir="F:\\Jie\\Shire_follow_up\\03_Results\\for_new200K&973\\"
, iters=20
, n.simu=5
, recall_tar=seq(0.5, 0.05, -0.05)
)
write.csv(perf_new200_973_iter20, paste0("F:\\Jie\\Shire_follow_up\\03_Results\\for_new200K&973\\perf_baggingRF_200K.csv"))
perf_new200_973_iter20
perf_new200_973_iter1 <- get_perf_allSimu(outdir="F:\\Jie\\Shire_follow_up\\03_Results\\for_new200K&973\\"
, iters=1
, n.simu=5
, recall_tar=seq(0.5, 0.05, -0.05)
)
write.csv(perf_new200_973_iter20, paste0("F:\\Jie\\Shire_follow_up\\03_Results\\for_new200K&973\\iters=20\\perf_baggingRF_200K.csv"))
write.csv(perf_new200_973_iter1, paste0("F:\\Jie\\Shire_follow_up\\03_Results\\for_new200K&973\\iters=1\\perf_baggingRF_200K.csv"))
perf_new200_973_iter20
perf_new200_973_iter1
perf_all <- lapply(1:5, function(i){
read.csv("F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233\\iters=20\\simu", i, "\\perf_on3M.csv")
})
perf_all <- lapply(1:5, function(i){
read.csv(paste0("F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233\\iters=20\\simu", i, "\\perf_on3M.csv"))
})
perf_all
perf_all_df <- ldply(perf_all, quickdf)
perf_all_df
perf_all_df <- ldply(perf_all, rbind)
perf_all_df
perf_all_df <- ldply(perf_all, cbind)
perf_all_df
i=1
x=read.csv(paste0("F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233\\iters=20\\simu", i, "\\perf_on3M.csv"))
x
perf_all <- lapply(1:5, function(i){
x=read.csv(paste0("F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233\\iters=20\\simu", i, "\\perf_on3M.csv"))
x1=x[, 2]
})
perf_all_df <- ldply(perf_all, cbind)
perf_all_df
class(x)
perf_all <- lapply(1:5, function(i){
x=read.csv(paste0("F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233\\iters=20\\simu", i, "\\perf_on3M.csv"))
})
perf_all_df <- ldply(perf_all, quickdf)
perf_all_df
perf_all_df1 <- perf_all_df %>% group_by(X) %>% summarise(mean)
perf_all_df1
perf_all_df1 <- perf_all_df %>% group_by(X) %>% summarize_each(mean)
perf_all_df1 <- perf_all_df %>% group_by(X) %>% summarize_each(mean, x)
perf_all_df1 <- perf_all_df %>% group_by(X) %>% summarize_each(mean, one_of(x))
perf_all_df1 <- perf_all_df %>% group_by(X) %>% summarize_each(., mean, one_of(x))
perf_all_df1 <- perf_all_df %>% group_by(X) %>% summarize_each(., mean)
?summarize
perf_all_df1 <- perf_all_df %>% group_by(X) %>% summarize(., mean(x))
perf_all_df1
perf_all_df1 <- perf_all_df %>% group_by(., X) %>% summarize(., mean(x))
perf_all_df1
dim(perf_all_df)
perf_all_df1 <- perf_all_df %>% group_by(., X)
perf_all_df1
perf_all_df1 <- perf_all_df %>% group_by(., X) %>% summarise(., mean(x))
perf_all_df1
summarise(group_by(perf_all_df, X), mean(x))
perf_all_df$X
perf_all_df1 <- tbl_df(perf_all_df) %>% group_by(., X) %>% summarise(., mean(x))
perf_all_df1
detach(plyr)
library(dplyr)
detach("plyr")
library(dplyr)
perf_all_df1 <- tbl_df(perf_all_df) %>% group_by(., X) %>% summarise(., mean(x))
perf_all_df1
perf_all_df1 <- tbl_df(perf_all_df) %>% group_by(., X) %>% summarize(., mean(x))
perf_all_df1
perf_all_df1 <- tbl_df(perf_all_df) %>% group_by(., X) %>% summarize_each(., mean(x))
detach("package:plyr", unload=TRUE)
library(dplyr)
perf_all_df1 <- tbl_df(perf_all_df) %>% group_by(., X) %>% summarize(., mean(x))
perf_all_df1
summarize_perf_3M <- function(outdir, iters){
perf_all <- lapply(1:5, function(i){
x=read.csv(paste0(outdir, "iters=", iters, "\\simu", i, "\\perf_on3M.csv"))
})
perf_all_df <- ldply(perf_all, quickdf)
detach("package:plyr", unload=TRUE)
library(dplyr)
perf_all_df1 <- tbl_df(perf_all_df) %>% group_by(., X) %>% summarize(., mean(x))
write.csv(perf_all_df1, paste0(outdir, "iters=", iters, "\\perf_on3M_allSimu.csv"))
library(plyr)
}
summarize_perf_3M(outdir="F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233\\"
, iters=1)
summarize_perf_3M <- function(outdir, iters){
perf_all <- lapply(1:5, function(i){
x=read.csv(paste0(outdir, "iters=", iters, "\\simu", i, "\\perf_on3M.csv"))
})
library(plyr)
perf_all_df <- ldply(perf_all, quickdf)
detach("package:plyr", unload=TRUE)
library(dplyr)
perf_all_df1 <- tbl_df(perf_all_df) %>% group_by(., X) %>% summarize(., mean(x))
write.csv(perf_all_df1, paste0(outdir, "iters=", iters, "\\perf_on3M_allSimu.csv"))
library(plyr)
}
summarize_perf_3M(outdir="F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233\\"
, iters=1)
summarize_perf_3M(outdir="F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233\\"
, iters=20)
summarize_perf_3M(outdir="F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233\\"
, iters=200)
perf_Dong_iter200 <- get_perf_allSimu(outdir="F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233(oneSimu)\\"
, iters=200
, n.simu=1
, recall_tar=seq(0.5, 0.05, -0.05)
)
write.csv(perf_Dong_iter200, paste0("F:\\Jie\\Shire_follow_up\\03_Results\\for_old200K&1233(oneSimu)\\perf_200K.csv"))
perf_Dong_iter200
# Apr15
# main function for running bagging forest and performance
rm(list=ls())
# R work directory
wk_dir = "F:\\Jie\\Shire_follow_up\\02_Code\\HAE_R_codes_Dec15\\"
# Setup R work directory
setwd(wk_dir)
# Load R packages
source("loadpackage.R")
# Auxiliary functions
source("auxfunctions.R")
#
source("funs_baggingRF.R")
t0 <- proc.time()
run_perf_3M_forPRcurve(outDir="F:\\Jie\\Shire_follow_up\\03_Results\\for_new200K&973\\"
, wk_dir=wk_dir
, lasso_rf_iters=20
, n.simu=5
, recall_tar=seq(0.5, 0.05, -0.05)
, fileNm_3M='neg_3M_clean2335697'
, path_3M='F:\\Jie\\Shire_follow_up\\01_data\\newdata_200K_3M\\'
)
cat((proc.time()-t0)[3]/60, 'min!\n')
source("funs_baggingRF.R")
t0 <- proc.time()
run_perf_3M_forPRcurve(outDir="F:\\Jie\\Shire_follow_up\\03_Results\\for_new200K&973\\"
, wk_dir=wk_dir
, lasso_rf_iters=20
, n.simu=5
, recall_tar=seq(0.5, 0.05, -0.05)
, fileNm_3M='neg_3M_clean2335697'
, path_3M='F:\\Jie\\Shire_follow_up\\01_data\\newdata_200K_3M\\'
)
cat((proc.time()-t0)[3]/60, 'min!\n')
source("funs_baggingRF.R")
temp <- get_perf_allSimu_forPRcurve(outdir="F:\\Jie\\Shire_follow_up\\03_Results\\for_new200K&973\\"
, iters=20
, n.simu=5
, recall_tar=seq(0.5, 0.05, -0.05)
)
